"""
Module: parser

This module defines the `Parser` class, which is responsible for parsing input source code into 
an abstract syntax tree (AST). The parser processes tokens generated by the tokenizer, validating 
the syntax and producing a structured representation that can be executed or further compiled.

Classes:
    Parser: A class that parses expressions, terms, factors, statements, and more into AST nodes.

Functions:
    parse_expression(): Parses an expression, including addition and subtraction.
    parse_term(): Parses a term, handling multiplication and division.
    parse_factor(): Parses factors, such as numbers, variables, and function calls.
    parse_statement(): Parses individual statements like variable declarations,
    function calls, loops, etc.
    parse_block(): Parses a block of statements.
    parse_rel_expression(): Parses relational expressions like greater than,
    less than, and equality checks.
    parse_bool_term(): Parses terms in boolean expressions with 'and'.
    parse_bool_expression(): Parses boolean expressions with 'or'.
    run(code): Initializes the tokenizer with the source code and starts the parsing process.
"""


from tokenizer import Tokenizer
from nodes import *


class Parser:
    """
    A class that parses input source code into an abstract syntax tree (AST).

    Methods:
        parse_expression(): Parses an expression from the input stream.
        parse_term(): Parses a term from the input stream.
        parse_factor(): Parses a factor from the input stream.
        parse_statement(): Parses a statement from the input token stream.
        parse_block(): Parses a block of statements.
        parse_rel_expression(): Parses a relational expression.
        parse_bool_term(): Parses a boolean term.
        parse_bool_expression(): Parses a boolean expression.
        run(code): Initializes the tokenizer with the source code and starts the parsing process
    """
    my_tokenizer: Tokenizer

    def __init__(self):
        pass

    @staticmethod
    def parse_expression():
        """
        Parses an expression from the input stream.

        Returns:
            The parsed expression.

        Raises:
            SyntaxError: If an unexpected token is encountered.
        """

        result = Parser.parse_term()
        while (
            Parser.my_tokenizer.next.typ in ["PLUS", "MINUS"]
        ):
            if Parser.my_tokenizer.next.typ == "PLUS":
                Parser.my_tokenizer.select_next()
                result = BinOp("+", [result, Parser.parse_term()])
            elif Parser.my_tokenizer.next.typ == "MINUS":
                Parser.my_tokenizer.select_next()
                result = BinOp("-", [result, Parser.parse_term()])

            else:
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                    at {Parser.my_tokenizer.position}"""
                )
        return result

    @staticmethod
    def parse_term():
        """
        Parses a term from the input string.

        Returns:
            The parsed term.

        Raises:
            SyntaxError: If an unexpected token is encountered.
        """


        result = Parser.parse_factor()
        while (
            Parser.my_tokenizer.next.typ in ["MULT", "DIV"]
        ):
            if Parser.my_tokenizer.next.typ == "MULT":
                Parser.my_tokenizer.select_next()
                result = BinOp("*", [result, Parser.parse_factor()])
            elif Parser.my_tokenizer.next.typ == "DIV":
                Parser.my_tokenizer.select_next()
                result = BinOp("/", [result, Parser.parse_factor()])

            else:
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position} """
                )

        return result

    @staticmethod
    def parse_factor():
        """
        Parses a factor from the input stream.

        Returns:
            - If the next token is a NUMBER, returns an IntVal node with the value of the token.
            - If the next token is a PLUS, returns a UnOp node with the
            operator "+" and the parsed factor as its child.
            - If the next token is a MINUS, returns a UnOp node with the
            operator "-" and the parsed factor as its child.
            - If the next token is "not", returns a UnOp node with the
            operator "not" and the parsed factor as its child.
            - If the next token is LPAREN, returns the result of parsing a
            boolean expression enclosed in parentheses.
            - If the next token is an ID, returns an Identifier node with the value of the token.
            - If the next token is "read", returns a ReadNode.
            - If the next token is a STRING, returns a StrVal node with the value of the token.

        Raises:
            - SyntaxError: If an unexpected token is encountered.

        """
        if Parser.my_tokenizer.next.typ == "NUMBER":
            result = IntVal(value=Parser.my_tokenizer.next.value, children=[])
            Parser.my_tokenizer.select_next()
            return result
        if Parser.my_tokenizer.next.typ == "PLUS":
            Parser.my_tokenizer.select_next()
            return UnOp("+", [Parser.parse_factor()])
        if Parser.my_tokenizer.next.typ == "MINUS":
            Parser.my_tokenizer.select_next()
            return UnOp("-", [Parser.parse_factor()])
        if Parser.my_tokenizer.next.typ == "not":
            Parser.my_tokenizer.select_next()
            return UnOp("not", [Parser.parse_factor()])
        if Parser.my_tokenizer.next.typ == "LPAREN":
            Parser.my_tokenizer.select_next()
            result = Parser.parse_bool_expression()
            if Parser.my_tokenizer.next.typ != "RPAREN":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position} """
                )
            Parser.my_tokenizer.select_next()
            return result
        if Parser.my_tokenizer.next.typ == "ID":
            result = Identifier(value=Parser.my_tokenizer.next.value, children=[])
            Parser.my_tokenizer.select_next()
            return result
        if Parser.my_tokenizer.next.typ == "read":
            Parser.my_tokenizer.select_next()
            if Parser.my_tokenizer.next.typ != "LPAREN":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position} """
                )
            Parser.my_tokenizer.select_next()
            if Parser.my_tokenizer.next.typ != "RPAREN":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position} """
                )
            Parser.my_tokenizer.select_next()
            return ReadNode(value=0, children=[])
        if Parser.my_tokenizer.next.typ == "STRING":
            result = StrVal(value=Parser.my_tokenizer.next.value, children=[])
            Parser.my_tokenizer.select_next()
            return result
        raise SyntaxError(
            f"""Unexpected token {Parser.my_tokenizer.next.typ}
                at {Parser.my_tokenizer.position} """
            )

    @staticmethod
    def parse_statement():
        """
        Parses a statement from the input token stream.

        Returns:
            Statement: The parsed statement.

        Raises:
            SyntaxError: If an unexpected token is encountered.
        """
        # code implementation...
        if Parser.my_tokenizer.next.typ == "ENDL":
            Parser.my_tokenizer.select_next()
            return NoOp()

        if Parser.my_tokenizer.next.typ == "ID":
            iden = Identifier(value=Parser.my_tokenizer.next.value, children=[])
            Parser.my_tokenizer.select_next()
            if Parser.my_tokenizer.next.typ == "=":
                Parser.my_tokenizer.select_next()
                return Assignment(
                    value=0, children=[iden, Parser.parse_bool_expression()]
                )
            if Parser.my_tokenizer.next.typ == "LPAREN":
                Parser.my_tokenizer.select_next()
                children = []
                if Parser.my_tokenizer.next.typ != "RPAREN":
                    children.append(Parser.parse_bool_expression())
                    while Parser.my_tokenizer.next.typ == "COMMA":
                        Parser.my_tokenizer.select_next()
                        children.append(Parser.parse_bool_expression())
                if Parser.my_tokenizer.next.typ != "RPAREN":
                    raise SyntaxError(
                        f"""Unexpected token {Parser.my_tokenizer.next.typ}
                          at {Parser.my_tokenizer.position}"""
                    )
                Parser.my_tokenizer.select_next()
                return FuncCall(value=iden.value, children=children)
            raise SyntaxError(
                f"""Unexpected token {Parser.my_tokenizer.next.typ}
                at {Parser.my_tokenizer.position}
                 with value {Parser.my_tokenizer.next.value}"""
                )

        if (
            Parser.my_tokenizer.next.typ == "int"
            or Parser.my_tokenizer.next.typ == "string"
        ):
            var_type = Parser.my_tokenizer.next.typ
            type_node = TypeNode(value=var_type, children=[])
            Parser.my_tokenizer.select_next()
            if Parser.my_tokenizer.next.typ != "ID":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position}"""
                )
            iden = Identifier(value=Parser.my_tokenizer.next.value, children=[])
            Parser.my_tokenizer.select_next()
            if Parser.my_tokenizer.next.typ == "=":
                Parser.my_tokenizer.select_next()
                value = Parser.parse_bool_expression()
                if var_type == "int" and not isinstance(value, IntVal):
                    raise SyntaxError(f"Cannot assign {value} to int")
                if var_type == "string" and not isinstance(value, StrVal):
                    raise SyntaxError(f"Cannot assign {value} to string")
                return VarDec(value=0, children=[iden, type_node, value])
            return VarDec(value=0, children=[iden, type_node])

        if Parser.my_tokenizer.next.typ == "print":
            Parser.my_tokenizer.select_next()
            if Parser.my_tokenizer.next.typ != "LPAREN":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position}"""
                )
            Parser.my_tokenizer.select_next()
            result = Parser.parse_bool_expression()
            if Parser.my_tokenizer.next.typ != "RPAREN":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position}"""
                )
            Parser.my_tokenizer.select_next()
            return PrintNode(value=0, children=[result])

        if Parser.my_tokenizer.next.typ == "while":
            Parser.my_tokenizer.select_next()
            condition = Parser.parse_bool_expression()
            while Parser.my_tokenizer.next.typ == "ENDL":
                Parser.my_tokenizer.select_next()
            if Parser.my_tokenizer.next.typ != "LBRACE":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position}"""
                )
            Parser.my_tokenizer.select_next()
            statements = []
            while Parser.my_tokenizer.next.typ != "RBRACE":
                statements.append(Parser.parse_statement())
            Parser.my_tokenizer.select_next()
            block = Block(value=0, children=statements)
            while_node = WhileNode(children=[condition, block])
            return while_node

        if Parser.my_tokenizer.next.typ == "if":
            Parser.my_tokenizer.select_next()
            condition = Parser.parse_bool_expression()
            while Parser.my_tokenizer.next.typ == "ENDL":
                Parser.my_tokenizer.select_next()
            if Parser.my_tokenizer.next.typ != "LBRACE":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position}"""
                )
            Parser.my_tokenizer.select_next()
            statements = []
            while Parser.my_tokenizer.next.typ != "RBRACE":
                statements.append(Parser.parse_statement())
            Parser.my_tokenizer.select_next()
            if_block = Block(value=0, children=statements)
            if_node = IfNode(children=[condition, if_block])
            if Parser.my_tokenizer.next.typ == "else":
                Parser.my_tokenizer.select_next()
                if Parser.my_tokenizer.next.typ != "LBRACE":
                    raise SyntaxError(
                        f"""Unexpected token {Parser.my_tokenizer.next.typ}
                          at {Parser.my_tokenizer.position}"""
                    )
                Parser.my_tokenizer.select_next()
                else_statements = []
                while Parser.my_tokenizer.next.typ != "RBRACE":
                    else_statements.append(Parser.parse_statement())
                Parser.my_tokenizer.select_next()
                else_block = Block(value=0, children=else_statements)
                if_node = IfNode(children=[condition, if_block, else_block])
            return if_node

        if Parser.my_tokenizer.next.typ == "switch":
            Parser.my_tokenizer.select_next()
            if Parser.my_tokenizer.next.typ != "ID":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position}"""
                )
            switch_expr = Identifier(value=Parser.my_tokenizer.next.value, children=[])
            switch_children = [switch_expr]
            Parser.my_tokenizer.select_next()
            if Parser.my_tokenizer.next.typ != "LPAREN":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position}"""
                )
            Parser.my_tokenizer.select_next()

            while Parser.my_tokenizer.next.typ != "RPAREN":
                while Parser.my_tokenizer.next.typ == "ENDL":
                    Parser.my_tokenizer.select_next()
                if Parser.my_tokenizer.next.typ == "case":
                    Parser.my_tokenizer.select_next()
                    if Parser.my_tokenizer.next.typ == "NUMBER":
                        case_expr = IntVal(
                            value=Parser.my_tokenizer.next.value, children=[]
                        )
                        Parser.my_tokenizer.select_next()
                    elif Parser.my_tokenizer.next.typ == "STRING":
                        case_expr = StrVal(
                            value=Parser.my_tokenizer.next.value, children=[]
                        )
                        Parser.my_tokenizer.select_next()
                    else:
                        raise SyntaxError(
                            f"""Unexpected token {Parser.my_tokenizer.next.typ}
                              at {Parser.my_tokenizer.position}"""
                        )
                    while Parser.my_tokenizer.next.typ == "ENDL":
                        Parser.my_tokenizer.select_next()
                    if Parser.my_tokenizer.next.typ != "LBRACE":
                        raise SyntaxError(
                            f"""Unexpected token {Parser.my_tokenizer.next.typ}
                              at {Parser.my_tokenizer.position}"""
                        )
                    Parser.my_tokenizer.select_next()
                    case_statements = []
                    while Parser.my_tokenizer.next.typ != "RBRACE":
                        case_statements.append(Parser.parse_statement())
                    Parser.my_tokenizer.select_next()
                    case_block = Block(value=0, children=case_statements)
                    case_node = CaseNode(children=[case_expr, case_block])
                    switch_children.append(case_node)
                elif Parser.my_tokenizer.next.typ == "default":
                    Parser.my_tokenizer.select_next()
                    while Parser.my_tokenizer.next.typ == "ENDL":
                        Parser.my_tokenizer.select_next()
                    if Parser.my_tokenizer.next.typ != "LBRACE":
                        raise SyntaxError(
                            f"""Unexpected token {Parser.my_tokenizer.next.typ}
                              at {Parser.my_tokenizer.position}"""
                        )
                    Parser.my_tokenizer.select_next()
                    default_statements = []
                    while Parser.my_tokenizer.next.typ != "RBRACE":
                        default_statements.append(Parser.parse_statement())
                    Parser.my_tokenizer.select_next()
                    default_block = Block(value=0, children=default_statements)
                    default_node = DefaultNode(children=[default_block])
                    switch_children.append(default_node)
                elif Parser.my_tokenizer.next.typ == "RPAREN":
                    break
                else:
                    raise SyntaxError(
                        f"""Unexpected token {Parser.my_tokenizer.next.typ}
                          at {Parser.my_tokenizer.position}"""
                    )

            if Parser.my_tokenizer.next.typ != "RPAREN":
                raise SyntaxError(
                    f"""Unexpected token {Parser.my_tokenizer.next.typ}
                      at {Parser.my_tokenizer.position}"""
                )
            Parser.my_tokenizer.select_next()
            switch_node = SwitchNode(children=switch_children)
            return switch_node

        return Parser.parse_bool_expression()

    @staticmethod
    def parse_block():
        """
        Parses a block of statements.

        Returns:
            Block: The parsed block object.

        Raises:
            None.
        """
        result = Block(value=0, children=[])
        while Parser.my_tokenizer.next.typ != "EOF":
            result.children.append(Parser.parse_statement())
        return result

    @staticmethod
    def parse_rel_expression():
        """
        Parses a relational expression and returns the resulting expression.

        Returns:
            Expression: The resulting expression after parsing the relational expression.

        """
        result = Parser.parse_expression()
        if Parser.my_tokenizer.next.typ == "==":
            Parser.my_tokenizer.select_next()
            result = BinOp("==", [result, Parser.parse_expression()])
        elif Parser.my_tokenizer.next.typ == ">":
            Parser.my_tokenizer.select_next()
            result = BinOp(">", [result, Parser.parse_expression()])
        elif Parser.my_tokenizer.next.typ == "<":
            Parser.my_tokenizer.select_next()
            result = BinOp("<", [result, Parser.parse_expression()])
        return result

    @staticmethod
    def parse_bool_term():
        """
        Parses a boolean term.

        Returns:
            The parsed boolean term.

        Raises:
            None.
        """
        result = Parser.parse_rel_expression()
        while Parser.my_tokenizer.next.typ == "and":
            Parser.my_tokenizer.select_next()
            result = BinOp("and", [result, Parser.parse_rel_expression()])
        return result

    @staticmethod
    def parse_bool_expression():
        """
        Parses a boolean expression.

        Returns:
            The parsed boolean expression.

        Raises:
            None.
        """
        result = Parser.parse_bool_term()
        while Parser.my_tokenizer.next.typ == "or":
            Parser.my_tokenizer.select_next()
            result = BinOp("or", [result, Parser.parse_bool_term()])
        return result

    @staticmethod
    def run(code):
        """
        Executes the parser on the given code.

        Parameters:
        - code (str): The code to be parsed.

        Returns:
        - result: The result of parsing the code.

        Raises:
        - SyntaxError: If an unexpected token is encountered.
        """
        Parser.my_tokenizer = Tokenizer(code, 0)
        Parser.my_tokenizer.select_next()
        result = Parser.parse_block()
        if Parser.my_tokenizer.next.typ != "EOF":
            raise SyntaxError(
                f"""Unexpected token {Parser.my_tokenizer.next.typ}
                  at {Parser.my_tokenizer.position} """
            )
        return result
